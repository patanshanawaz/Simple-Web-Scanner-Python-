import requests
from bs4 import BeautifulSoup

def scan_website(url):
    print(f"\nğŸ” Scanning: {url}")
    
    try:
        response = requests.get(url)
        print(f"âœ… Status Code: {response.status_code}")
        print(f"ğŸ›¡ Server: {response.headers.get('Server')}")
        print(f"ğŸ” X-Frame-Options: {response.headers.get('X-Frame-Options')}")
        print(f"ğŸ›¡ Content-Security-Policy: {response.headers.get('Content-Security-Policy')}")

        soup = BeautifulSoup(response.text, 'html.parser')
        links = [a['href'] for a in soup.find_all('a', href=True)]
        print(f"ğŸ”— Found {len(links)} links")

        if response.status_code == 200:
            print("ğŸŸ¢ Website is reachable.")
        elif response.status_code == 403:
            print("ğŸ”´ Access is forbidden.")
        elif response.status_code == 404:
            print("ğŸ”´ Page not found.")
        else:
            print("âš  Something else happened.")
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    target_url = input("ğŸŒ Enter a website URL (with http/https): ")
    scan_website(target_url)
